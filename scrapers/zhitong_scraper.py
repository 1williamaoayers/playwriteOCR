#!/usr/bin/env python3
"""
æ™ºé€šè´¢ç»çˆ¬è™«
1. è®¿é—®é¦–é¡µ
2. è¾“å…¥å…³é”®è¯ï¼Œç‚¹æœç´¢
3. å¤„ç†æ–°çª—å£ï¼ˆå¸¦tokenï¼‰
4. ç‚¹"å¿«è®¯"tabï¼Œæ»šåŠ¨é‡‡é›†
"""

import sys
import time
from datetime import datetime
from playwright.sync_api import sync_playwright

def scrape_zhitong(keyword: str, target_count: int = 20):
    results = []
    seen = set()
    
    with sync_playwright() as p:
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        browser = p.chromium.launch(headless=True, args=['--no-sandbox'])
        context = browser.new_context(viewport={'width': 1920, 'height': 1080})
        page = context.new_page()
        
        try:
            # 1. è®¿é—®é¦–é¡µ
            print("ğŸŒ è®¿é—®é¦–é¡µ...")
            page.goto('https://www.zhitongcaijing.com/', wait_until='domcontentloaded', timeout=60000)
            time.sleep(3)
            
            # 2. è¾“å…¥å…³é”®è¯
            print(f"ğŸ” æœç´¢: {keyword}")
            search_input = page.locator('input.search-input-head').first
            search_input.fill(keyword)
            time.sleep(1)
            
            # 3. ç›‘å¬æ–°çª—å£ï¼Œç‚¹å‡»æœç´¢
            with context.expect_page() as new_page_info:
                page.click('text=æœç´¢', force=True)
            
            new_page = new_page_info.value
            print(f"ğŸ“„ æ–°çª—å£: {new_page.url[:80]}...")
            time.sleep(3)
            
            # 4. ç‚¹å‡»"å¿«è®¯"tab
            print("ğŸ‘‰ ç‚¹å‡» 'å¿«è®¯' Tab...")
            new_page.click('text=å¿«è®¯', force=True, timeout=10000)
            time.sleep(2)
            
            print(f"ğŸ“Š é‡‡é›†å¿«è®¯ (ç›®æ ‡: {target_count})...")
            
            # 5. æ»šåŠ¨é‡‡é›†
            for scroll_round in range(10):
                items = new_page.evaluate("""() => {
                    var results = [];
                    
                    // æŸ¥æ‰¾å¿«è®¯æ¡ç›®
                    document.querySelectorAll('a, div, p').forEach(function(el) {
                        var text = el.innerText || '';
                        
                        // åŒ¹é…æ—¶é—´æ ¼å¼ 2026-01-16 17:40:02
                        var timeMatch = text.match(/(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2})/);
                        if (timeMatch && text.length > 30 && text.length < 800) {
                            var lines = text.split('\\n');
                            var title = '';
                            
                            // æ‰¾æ ‡é¢˜ï¼ˆã€å¼€å¤´æˆ–è¾ƒé•¿çš„è¡Œï¼‰
                            for (var i = 0; i < lines.length; i++) {
                                var line = lines[i].trim();
                                if (line.length > 15 && line.indexOf('2026') < 0) {
                                    title = line;
                                    break;
                                }
                            }
                            
                            if (title) {
                                results.push({
                                    title: title.substring(0, 200),
                                    time: timeMatch[1],
                                    url: el.href || ''
                                });
                            }
                        }
                    });
                    
                    return results;
                }""")
                
                for item in items:
                    uid = item['title'][:30]
                    if uid not in seen:
                        seen.add(uid)
                        results.append(item)
                
                print(f"ğŸ“Š [ç¬¬{scroll_round+1}è½®] é‡‡é›†: {len(results)} æ¡")
                
                if len(results) >= target_count:
                    break
                
                # æ»šåŠ¨åŠ è½½æ›´å¤š
                new_page.mouse.wheel(0, 800)
                time.sleep(2)
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        finally:
            browser.close()
    
    # æŒ‰æ—¶é—´æ’åº
    results.sort(key=lambda x: x.get('time', ''), reverse=True)
    return results[:target_count]

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python zhitong_scraper.py <å…³é”®è¯> [æ•°é‡] [--json]")
        sys.exit(1)
    
    # è§£æå‚æ•°
    keyword = sys.argv[1]
    limit = 20
    json_mode = False
    
    for arg in sys.argv[2:]:
        if arg == '--json':
            json_mode = True
        elif arg.isdigit():
            limit = int(arg)
    
    # JSON æ¨¡å¼
    if json_mode:
        import json as json_lib
        import io, sys as sys_module
        old_stdout = sys_module.stdout
        sys_module.stdout = io.StringIO()
        data = scrape_zhitong(keyword, limit)
        sys_module.stdout = old_stdout
        print(json_lib.dumps(data, ensure_ascii=False))
        return
    
    # æ™®é€šæ¨¡å¼
    print(f"{'='*50}")
    print(f"ğŸ“° æ™ºé€šè´¢ç»çˆ¬è™« | {keyword} | ç›®æ ‡: {limit}")
    print(f"{'='*50}")
    
    start = time.time()
    data = scrape_zhitong(keyword, limit)
    elapsed = time.time() - start
    
    if data:
        filename = f"{keyword}_æ™ºé€šè´¢ç»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {keyword} æ™ºé€šè´¢ç»å¿«è®¯\n\n")
            f.write(f"> é‡‡é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"> æ•°é‡: {len(data)}\n")
            f.write(f"> è€—æ—¶: {elapsed:.1f}ç§’\n\n---\n\n")
            for i, item in enumerate(data, 1):
                f.write(f"## {i}. {item['title']}\n\n")
                if item.get('time'): f.write(f"- **æ—¶é—´**: {item['time']}\n")
                if item.get('url'): f.write(f"- **é“¾æ¥**: {item['url']}\n")
                f.write("\n")
        
        print(f"\n{'='*50}")
        print(f"âœ… å®Œæˆ: {len(data)}æ¡ | {elapsed:.1f}ç§’")
        print(f"ğŸ“„ ä¿å­˜: {filename}")
        print(f"{'='*50}")
    else:
        print(f"\nâš ï¸ æ— æ•°æ®")

if __name__ == "__main__":
    main()

