#!/usr/bin/env python3
"""
åå°”è¡—è§é—»èµ„è®¯çˆ¬è™« - DOMè§£æç‰ˆ v2
ç”¨æ³•ï¼špython wallstreet_scraper.py "å…³é”®è¯"
"""

import sys
import re
import time
import os
import urllib.parse
from datetime import datetime
from playwright.sync_api import sync_playwright


def scrape(keyword: str) -> list:
    """çˆ¬å–åå°”è¡—è§é—»ï¼ˆç›´æ¥ä»DOMå±æ€§æå–æ—¶é—´ï¼‰"""
    news = []
    os.makedirs('screenshots', exist_ok=True)
    
    with sync_playwright() as p:
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        browser = p.chromium.launch(headless=True, args=['--no-sandbox'])
        
        context = browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0',
        )
        page = context.new_page()
        page.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        try:
            # ç›´æ¥ä½¿ç”¨ URL ç¼–ç è®¿é—®
            encoded_keyword = urllib.parse.quote(keyword)
            url = f'https://wallstreetcn.com/search?q={encoded_keyword}&type=live'
            print(f"ğŸ“„ æ‰“å¼€: {url}")
            page.goto(url, wait_until='domcontentloaded', timeout=60000)
            
            print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
            time.sleep(5)
            
            print("ğŸ“° åŠ è½½æ›´å¤šå†…å®¹...")
            
            # å¤šæ¬¡ç‚¹å‡»"åŠ è½½æ›´å¤š"è·å–æ›´å¤šå†…å®¹
            for i in range(5):  # ç‚¹å‡»5æ¬¡
                try:
                    # æ»šåŠ¨åˆ°åº•éƒ¨
                    page.evaluate('window.scrollTo(0, document.body.scrollHeight)')
                    time.sleep(1)
                    
                    # ç‚¹å‡»"åŠ è½½æ›´å¤š"æŒ‰é’®
                    load_more = page.locator('text=åŠ è½½æ›´å¤š')
                    if load_more.count() > 0:
                        load_more.click(timeout=3000)
                        time.sleep(2)
                        print(f"  ğŸ“¥ ç¬¬{i+1}æ¬¡åŠ è½½...")
                    else:
                        break
                except:
                    break
            
            # æœ€ç»ˆæˆªå›¾
            page.screenshot(path='screenshots/wallstreet_page.png')
            print("ğŸ“· æˆªå›¾: wallstreet_page.png")
            
            print("ğŸ“° æå–æ–°é—»...")
            
            # ç›´æ¥é€‰æ‹© live-item å…ƒç´ 
            items = page.locator('div.live-item').all()
            print(f"  æ‰¾åˆ° {len(items)} æ¡å¿«è®¯")
            
            for item in items:
                try:
                    # ä» time å…ƒç´ çš„ datetime å±æ€§ç›´æ¥è·å–ç²¾ç¡®æ—¶é—´
                    # æ ¼å¼ï¼š2026-01-16T18:58:31.000+08:00
                    time_elem = item.locator('time.live-item_created')
                    if time_elem.count() == 0:
                        continue
                    
                    datetime_attr = time_elem.get_attribute('datetime')
                    if not datetime_attr:
                        continue
                    
                    # è§£æISOæ—¶é—´
                    # å»æ‰æ—¶åŒºå’Œæ¯«ç§’
                    dt_str = datetime_attr[:19]  # 2026-01-16T18:58:31
                    time_obj = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')
                    
                    # æå–æ ‡é¢˜ï¼ˆã€ã€‘å†…çš„å†…å®¹ï¼‰
                    title = ""
                    title_elem = item.locator('div.live-item_title')
                    if title_elem.count() > 0:
                        title = title_elem.inner_text().strip()
                    
                    # æå–æ­£æ–‡å†…å®¹
                    content = ""
                    content_elem = item.locator('div.live-item_html')
                    if content_elem.count() > 0:
                        content = content_elem.inner_text().strip()
                    
                    # åˆå¹¶æ ‡é¢˜å’Œæ­£æ–‡
                    full_text = title
                    if content:
                        full_text = title + "\n" + content if title else content
                    
                    if len(full_text) < 10:
                        continue
                    
                    news.append({
                        'title': title,
                        'content': content,
                        'full_text': full_text[:500],  # é™åˆ¶é•¿åº¦
                        'time': time_obj,
                    })
                except Exception as e:
                    continue
            
            print(f"ğŸ“Š å…±æå–: {len(news)} æ¡")
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        finally:
            browser.close()
            print("ğŸ”’ æµè§ˆå™¨å…³é—­")
    
    return news


def main():
    # è§£æå‚æ•°: keyword [limit] [--json]
    keyword = "å°ç±³é›†å›¢"
    json_mode = False
    
    args = [arg for arg in sys.argv[1:] if arg != '--json']
    json_mode = '--json' in sys.argv
    
    if len(args) >= 1:
        keyword = args[0]
    
    # JSON æ¨¡å¼
    if json_mode:
        import json as json_lib
        import io, sys as sys_module
        old_stdout = sys_module.stdout
        sys_module.stdout = io.StringIO()
        all_news = scrape(keyword)
        sys_module.stdout = old_stdout
        # è½¬æ¢ä¸º JSON å¯åºåˆ—åŒ–æ ¼å¼
        output = []
        seen = set()
        for n in all_news:
            key = n['title'][:40]
            if key not in seen:
                seen.add(key)
                output.append({
                    'title': n['title'],
                    'summary': n.get('content', ''),  # ä¿ç•™å®Œæ•´å†…å®¹
                    'time': n['time'].strftime('%Y-%m-%d %H:%M') if hasattr(n['time'], 'strftime') else str(n['time']),
                    'url': ''
                })
        output.sort(key=lambda x: x['time'], reverse=True)
        print(json_lib.dumps(output, ensure_ascii=False))
        return
    
    # æ™®é€šæ¨¡å¼
    print("=" * 60)
    print(f"ğŸ¯ åå°”è¡—è§é—»çˆ¬è™« | å…³é”®è¯: {keyword}")
    print("=" * 60)
    
    start = time.time()
    all_news = scrape(keyword)
    elapsed = time.time() - start
    
    # å»é‡
    seen = set()
    unique = []
    for n in all_news:
        key = n['title'][:40]
        if key not in seen:
            seen.add(key)
            unique.append(n)
    
    # æŒ‰æ—¶é—´æ’åº
    unique.sort(key=lambda x: x['time'], reverse=True)
    # è¾“å‡ºå…¨éƒ¨ï¼ˆä¸å†é™åˆ¶20æ¡ï¼‰
    results = unique
    
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š åŸå§‹: {len(all_news)} | å»é‡: {len(unique)} | è¾“å‡º: {len(results)}")
    print("=" * 60)
    
    if results:
        print(f"\nğŸ“° {keyword} åå°”è¡—è§é—»:\n")
        for i, n in enumerate(results, 1):
            t = n['time'].strftime('%m-%d %H:%M')
            title = n['title'][:65] + '...' if len(n['title']) > 65 else n['title']
            print(f"[{i}] [{t}] {title}")
        
        # ä¿å­˜ MD
        md = f"{keyword}_åå°”è¡—è§é—»_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(md, 'w', encoding='utf-8') as f:
            f.write(f"# {keyword} åå°”è¡—è§é—»\n\n")
            f.write(f"> é‡‡é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"> æ¥æº: åå°”è¡—è§é—»å¿«è®¯\n")
            f.write(f"> å…± {len(results)} æ¡\n\n---\n\n")
            for i, n in enumerate(results, 1):
                t = n['time'].strftime('%Y-%m-%d %H:%M')
                f.write(f"## {i}. {n['title']}\n\n")
                f.write(f"**æ—¶é—´**: {t}\n\n")
                if n.get('content'):
                    f.write(f"{n['content']}\n\n")
                f.write(f"---\n\n")
        
        print(f"\nğŸ’¾ å·²ä¿å­˜: {md}")
    else:
        print("\nâš ï¸ æœªæå–åˆ°æ–°é—»")
    
    print(f"â±ï¸ è€—æ—¶: {elapsed:.1f}s")


if __name__ == "__main__":
    main()

