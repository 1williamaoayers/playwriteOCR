#!/usr/bin/env python3
"""
ä¸œæ–¹è´¢å¯Œçˆ¬è™«
URL: https://so.eastmoney.com/news/s?keyword=å…³é”®è¯&type=content
ç›´æ¥æ‰“å¼€å°±æ˜¯ èµ„è®¯>æ­£æ–‡ï¼Œç¿»é¡µç‚¹åº•æ é¡µç 
"""

import sys
import time
from datetime import datetime
from playwright.sync_api import sync_playwright

def scrape_eastmoney(keyword: str, target_count: int = 20):
    results = []
    seen = set()
    
    with sync_playwright() as p:
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        browser = p.chromium.launch(headless=True, args=['--no-sandbox'])
        page = browser.new_page(viewport={'width': 1920, 'height': 1080})
        
        try:
            # ç›´æ¥è®¿é—®ï¼Œä¸éœ€è¦ç‚¹Tab
            url = f"https://so.eastmoney.com/news/s?keyword={keyword}&type=content"
            print(f"ğŸŒ è®¿é—®: {url}")
            page.goto(url, wait_until='domcontentloaded', timeout=60000)
            time.sleep(3)
            
            page_num = 1
            while len(results) < target_count:
                print(f"ğŸ“– ç¬¬ {page_num} é¡µ...")
                
                # é‡‡é›† .news_item
                items = page.evaluate("""() => {
                    var results = [];
                    document.querySelectorAll('.news_item').forEach(function(item) {
                        var text = item.innerText || '';
                        var lines = text.split('\\n');
                        var title = lines[0].trim();
                        
                        // æ‘˜è¦ï¼ˆç¬¬äºŒè¡Œé€šå¸¸æ˜¯æ—¶é—´+æ‘˜è¦ï¼‰
                        var summary = '';
                        if (lines.length > 1) {
                            // è·³è¿‡æ—¶é—´ï¼Œå–æ‘˜è¦å†…å®¹
                            var content = lines.slice(1).join(' ').trim();
                            // å»æ‰æ—¶é—´å’Œé“¾æ¥
                            content = content.replace(/\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}\\s*-?/g, '');
                            content = content.replace(/http[^\\s]+/g, '');
                            summary = content.trim().substring(0, 200);
                        }
                        
                        // æ—¶é—´
                        var time = '';
                        var m = text.match(/(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2})/);
                        if (m) time = m[1];
                        
                        // é“¾æ¥
                        var urlEl = item.querySelector('.news_item_url');
                        var url = urlEl ? urlEl.innerText.trim() : '';
                        
                        if (title.length > 5) results.push({
                            title: title, 
                            summary: summary,
                            time: time, 
                            url: url
                        });
                    });
                    return results;
                }""")
                
                for item in items:
                    if item['title'][:30] not in seen:
                        seen.add(item['title'][:30])
                        results.append(item)
                
                print(f"   æœ¬é¡µ: {len(items)} æ¡, æ€»è®¡: {len(results)} æ¡")
                
                if len(results) >= target_count:
                    break
                
                # ç‚¹å‡»ä¸‹ä¸€é¡µé¡µç 
                page_num += 1
                try:
                    page.click(f'a:text-is("{page_num}")', timeout=3000)
                    time.sleep(2)
                except:
                    print("   ç¿»é¡µç»“æŸ")
                    break
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        finally:
            browser.close()
    
    # ä¿æŒé¡µé¢é¡ºåºï¼ˆé»˜è®¤æŒ‰ç›¸å…³æ€§æ’åºï¼‰
    return results[:target_count]

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python eastmoney_scraper.py <å…³é”®è¯> [æ•°é‡] [--json]")
        sys.exit(1)
    
    # è§£æå‚æ•°
    keyword = sys.argv[1]
    limit = 20
    json_mode = False
    
    for arg in sys.argv[2:]:
        if arg == '--json':
            json_mode = True
        elif arg.isdigit():
            limit = int(arg)
    
    # JSON æ¨¡å¼ï¼šé™é»˜è¿è¡Œï¼Œåªè¾“å‡º JSON
    if json_mode:
        import json as json_lib
        import io, sys as sys_module
        # æŠ‘åˆ¶ scrape å‡½æ•°å†…çš„ print è¾“å‡º
        old_stdout = sys_module.stdout
        sys_module.stdout = io.StringIO()
        data = scrape_eastmoney(keyword, limit)
        sys_module.stdout = old_stdout
        print(json_lib.dumps(data, ensure_ascii=False))
        return
    
    # æ™®é€šæ¨¡å¼ï¼šè¾“å‡ºè¿›åº¦å’Œä¿å­˜æ–‡ä»¶
    print(f"{'='*50}")
    print(f"ğŸ“ˆ ä¸œæ–¹è´¢å¯Œçˆ¬è™« | {keyword} | ç›®æ ‡: {limit}")
    print(f"{'='*50}")
    
    start = time.time()
    data = scrape_eastmoney(keyword, limit)
    elapsed = time.time() - start
    
    if data:
        filename = f"{keyword}_ä¸œæ–¹è´¢å¯Œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {keyword} ä¸œæ–¹è´¢å¯Œèµ„è®¯\n\n")
            f.write(f"> é‡‡é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"> æ•°é‡: {len(data)}\n")
            f.write(f"> è€—æ—¶: {elapsed:.1f}ç§’\n\n---\n\n")
            for i, item in enumerate(data, 1):
                f.write(f"## {i}. {item['title']}\n\n")
                if item.get('time'): f.write(f"- **æ—¶é—´**: {item['time']}\n")
                if item.get('summary'): f.write(f"- **æ‘˜è¦**: {item['summary']}\n")
                if item.get('url'): f.write(f"- **é“¾æ¥**: {item['url']}\n")
                f.write("\n")
        
        print(f"\n{'='*50}")
        print(f"âœ… å®Œæˆ: {len(data)}æ¡ | {elapsed:.1f}ç§’")
        print(f"ğŸ“„ ä¿å­˜: {filename}")
        print(f"{'='*50}")
    else:
        print(f"\nâš ï¸ æ— æ•°æ®")

if __name__ == "__main__":
    main()

