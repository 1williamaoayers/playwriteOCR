#!/usr/bin/env python3
"""
å¯Œé€”ç‰›ç‰›ç ”æŠ¥çˆ¬è™«
é‡‡é›†è·¯å¾„: æœç´¢ -> èµ„è®¯ -> ç ”æŠ¥
ä½¿ç”¨ dispatchEvent ç‚¹å‡»é¿å…å¼¹çª—å…³é—­
"""

import sys
import time
from datetime import datetime
from playwright.sync_api import sync_playwright

def scrape_futu_report(keyword: str, target_count: int = 50):
    """é‡‡é›†å¯Œé€”ç ”æŠ¥ - èµ„è®¯>ç ”æŠ¥å­æ """
    results = {}
    
    with sync_playwright() as p:
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        browser = p.chromium.launch(headless=True, args=['--no-sandbox'])
        context = browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0'
        )
        page = context.new_page()
        
        # APIæ‹¦æˆªå™¨
        def on_response(response):
            try:
                if response.status == 200:
                    url = response.url
                    if 'search' in url or 'report' in url or 'research' in url:
                        try:
                            data = response.json()
                            parse_api(data, results, keyword)
                        except:
                            pass
            except:
                pass

        page.on('response', on_response)
        
        try:
            # 1. è®¿é—®é¦–é¡µ
            print("ğŸŒ è®¿é—®: https://news.futunn.com/main/live")
            page.goto('https://news.futunn.com/main/live', wait_until='domcontentloaded', timeout=60000)
            time.sleep(3)
            
            # 2. è¾“å…¥æœç´¢è¯
            print(f"ğŸ” æœç´¢: {keyword}")
            search = page.locator('input.web_search-input').first
            search.click(force=True)
            time.sleep(0.3)
            search.fill(keyword)
            time.sleep(3)
            
            # 3. ä½¿ç”¨dispatchEventç‚¹å‡»èµ„è®¯Tab (å…³é”®ï¼)
            print("ğŸ‘‰ ç‚¹å‡» 'èµ„è®¯' Tab...")
            page.evaluate("""() => {
                var tabs = document.querySelectorAll('.web_search-tab-li');
                for (var i = 0; i < tabs.length; i++) {
                    if (tabs[i].innerText && tabs[i].innerText.indexOf('èµ„è®¯') >= 0) {
                        var event = new MouseEvent('click', {
                            view: window, bubbles: true, cancelable: true
                        });
                        tabs[i].dispatchEvent(event);
                        return;
                    }
                }
            }""")
            time.sleep(2)
            
            # 4. ä½¿ç”¨dispatchEventç‚¹å‡»ç ”æŠ¥å­Tab (å…³é”®ï¼é€‰æ‹©å™¨æ˜¯ web_search-sec-tab-li)
            print("ğŸ‘‰ ç‚¹å‡» 'ç ”æŠ¥' å­Tab...")
            page.evaluate("""() => {
                var tabs = document.querySelectorAll('.web_search-sec-tab-li');
                for (var i = 0; i < tabs.length; i++) {
                    if (tabs[i].innerText && tabs[i].innerText.trim() === 'ç ”æŠ¥') {
                        var event = new MouseEvent('click', {
                            view: window, bubbles: true, cancelable: true
                        });
                        tabs[i].dispatchEvent(event);
                        return;
                    }
                }
            }""")
            time.sleep(2)
            
            # æ£€æŸ¥å¼¹çª—çŠ¶æ€
            popup = page.evaluate("""() => {
                var panel = document.querySelector('.web_search-res-panel');
                return panel ? panel.offsetHeight > 0 : false;
            }""")
            
            if popup:
                print(f"âœ… å¼¹çª—æ‰“å¼€ï¼Œå¼€å§‹æ»šåŠ¨é‡‡é›† (ç›®æ ‡: {target_count})...")
                no_new = 0
                
                for i in range(100):
                    prev = len(results)
                    
                    # é‡‡é›†DOM
                    parse_dom(page, results, keyword)
                    
                    curr = len(results)
                    print(f"ğŸ“Š [ç¬¬{i+1}è½®] æ€»æ•°: {curr} (+{curr-prev})")
                    
                    if curr >= target_count:
                        print(f"âœ… è¾¾åˆ°ç›®æ ‡")
                        break
                    
                    if curr == prev:
                        no_new += 1
                    else:
                        no_new = 0
                    
                    if no_new >= 10:
                        print("ğŸ›‘ æ— æ›´å¤šæ•°æ®")
                        break
                    
                    # æ»šåŠ¨å¼¹çª—å†…å®¹
                    page.evaluate("""() => {
                        var panel = document.querySelector('.web_search-res-panel');
                        if (panel) panel.scrollTop += 500;
                    }""")
                    time.sleep(1)
            else:
                print("âš ï¸ å¼¹çª—å·²å…³é—­")
                
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        finally:
            browser.close()
            
    return list(results.values())

def parse_api(data, results, keyword):
    """è§£æAPIæ•°æ®"""
    if not isinstance(data, dict):
        return
    
    items = []
    if 'data' in data:
        d = data['data']
        if isinstance(d, dict):
            items.extend(d.get('report', []))
            items.extend(d.get('research', []))
            items.extend(d.get('list', []))
            items.extend(d.get('items', []))
        elif isinstance(d, list):
            items = d
    
    for item in items:
        if not isinstance(item, dict):
            continue
        title = (item.get('title') or '').replace('<em>', '').replace('</em>', '')
        if keyword not in title and 'å°ç±³' not in title and '01810' not in title:
            continue
        if len(title) < 10:
            continue
        
        uid = title[:30]
        if uid in results:
            continue
        
        ts = item.get('time') or item.get('publishTime') or 0
        try:
            if isinstance(ts, (int, float)) and ts > 1000000000:
                time_str = datetime.fromtimestamp(int(ts)).strftime('%Y-%m-%d %H:%M')
            else:
                time_str = str(ts) if ts else ''
        except:
            time_str = ''
        
        # æå–ç ”æŠ¥ç‰¹æœ‰ä¿¡æ¯
        org = item.get('orgName') or item.get('organization') or ''
        rating = item.get('rating') or item.get('ratingName') or ''
        
        results[uid] = {
            'title': title,
            'url': item.get('url', ''),
            'time': time_str,
            'org': org,
            'rating': rating,
            'source': 'API'
        }

def parse_dom(page, results, keyword):
    """è§£æDOMæ•°æ®"""
    try:
        items = page.evaluate("""(kw) => {
            var res = [];
            var links = document.querySelectorAll('a');
            for (var i = 0; i < links.length; i++) {
                var a = links[i];
                var text = a.innerText || '';
                var href = a.href || '';
                // ç ”æŠ¥é“¾æ¥é€šå¸¸åŒ…å« /report/ æˆ– /research/
                if ((text.indexOf('å°ç±³') >= 0 || text.indexOf(kw) >= 0 || text.indexOf('01810') >= 0) && 
                    text.length > 10 && 
                    (href.indexOf('/report/') >= 0 || href.indexOf('/research/') >= 0 || 
                     href.indexOf('/post/') >= 0 || href.indexOf('/notice/') >= 0)) {
                    res.push({
                        title: text.split('\\n')[0].substring(0, 200),
                        url: href
                    });
                }
            }
            return res;
        }""", keyword)
        
        for item in items:
            title = item.get('title', '')
            if len(title) < 10:
                continue
            uid = title[:30]
            if uid in results:
                continue
            results[uid] = {
                'title': title,
                'url': item.get('url', ''),
                'time': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'org': '',
                'rating': '',
                'source': 'DOM'
            }
    except:
        pass

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python futu_report_scraper.py <å…³é”®è¯> [æ•°é‡] [--json]")
        print("ç¤ºä¾‹: python futu_report_scraper.py å°ç±³é›†å›¢ 30")
        sys.exit(1)
    
    # è§£æå‚æ•°
    keyword = sys.argv[1]
    limit = 20
    json_mode = False
    
    for arg in sys.argv[2:]:
        if arg == '--json':
            json_mode = True
        elif arg.isdigit():
            limit = int(arg)
    
    if keyword == "01810":
        keyword = "å°ç±³é›†å›¢"
    
    # JSON æ¨¡å¼
    if json_mode:
        import json as json_lib
        import io, sys as sys_module
        old_stdout = sys_module.stdout
        sys_module.stdout = io.StringIO()
        data = scrape_futu_report(keyword, limit)
        sys_module.stdout = old_stdout
        print(json_lib.dumps(data, ensure_ascii=False))
        return
    
    # æ™®é€šæ¨¡å¼
    print(f"{'='*50}")
    print(f"ğŸ“ˆ å¯Œé€”ç ”æŠ¥çˆ¬è™« | {keyword} | ç›®æ ‡: {limit}")
    print(f"{'='*50}")
    
    start = time.time()
    data = scrape_futu_report(keyword, limit)
    elapsed = time.time() - start
    
    if data:
        try:
            data.sort(key=lambda x: x.get('time', ''), reverse=True)
        except:
            pass
        
        filename = f"{keyword}_å¯Œé€”ç ”æŠ¥_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {keyword} å¯Œé€”ç ”æŠ¥\n\n")
            f.write(f"> é‡‡é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"> æ¥æº: èµ„è®¯ > ç ”æŠ¥\n")
            f.write(f"> æ•°é‡: {len(data)}\n")
            f.write(f"> è€—æ—¶: {elapsed:.1f}ç§’\n\n---\n\n")
            
            for i, item in enumerate(data, 1):
                f.write(f"## {i}. {item['title']}\n\n")
                f.write(f"- **æ—¶é—´**: {item.get('time', 'N/A')}\n")
                if item.get('org'):
                    f.write(f"- **æœºæ„**: {item['org']}\n")
                if item.get('rating'):
                    f.write(f"- **è¯„çº§**: {item['rating']}\n")
                f.write(f"- **æ¥æº**: {item.get('source', 'N/A')}\n")
                if item.get('url'):
                    f.write(f"- **é“¾æ¥**: {item['url']}\n")
                f.write("\n")
        
        print(f"\n{'='*50}")
        print(f"âœ… å®Œæˆ: {len(data)}æ¡ | {elapsed:.1f}ç§’")
        print(f"ğŸ“„ ä¿å­˜: {filename}")
        print(f"{'='*50}")
    else:
        print(f"\nâš ï¸ æ— æ•°æ® | {elapsed:.1f}ç§’")

if __name__ == "__main__":
    main()

