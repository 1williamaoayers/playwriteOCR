#!/usr/bin/env python3
"""
æ ¼éš†æ±‡çˆ¬è™«
URL: https://www.gelonghui.com/search?keyword=å…³é”®è¯&type=news
æŒ‰é¡µé¢é¡ºåºé‡‡é›†ï¼ˆå·²æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼‰
"""

import sys
import time
from datetime import datetime
from playwright.sync_api import sync_playwright

def scrape_gelonghui(keyword: str, target_count: int = 20):
    """é‡‡é›†æ ¼éš†æ±‡æ–°é—» - æŒ‰é¡µé¢é¡ºåºï¼ˆæœ€æ–°åœ¨å‰ï¼‰"""
    results = []
    
    with sync_playwright() as p:
        print("ğŸš€ å¯åŠ¨æµè§ˆå™¨...")
        browser = p.chromium.launch(headless=True, args=['--no-sandbox'])
        page = browser.new_page(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0'
        )
        
        try:
            # è®¿é—®æœç´¢é¡µ
            url = f"https://www.gelonghui.com/search?keyword={keyword}&type=news"
            print(f"ğŸŒ è®¿é—®: {url}")
            page.goto(url, wait_until='domcontentloaded', timeout=60000)
            time.sleep(5)
            
            seen = set()
            
            # æŒ‰é¡µé¢é¡ºåºé‡‡é›†
            print(f"ğŸ“Š é‡‡é›†æ–°é—» (ç›®æ ‡: {target_count})...")
            
            for scroll_round in range(10):
                items = page.evaluate("""(targetCount) => {
                    var results = [];
                    
                    // æŒ‰DOMé¡ºåºè·å–æ–°é—»é“¾æ¥
                    var links = document.querySelectorAll('a[href*="/news/"]');
                    
                    links.forEach(function(a) {
                        var text = a.innerText || '';
                        if (text.length > 20 && text.length < 500) {
                            var lines = text.split('\\n');
                            var title = lines[0].trim();
                            
                            // æå–æ—¶é—´
                            var time = '';
                            var match = text.match(/æ ¼éš†æ±‡(\\d{1,2}æœˆ\\d{1,2}æ—¥)/);
                            if (match) {
                                time = match[1];
                            } else {
                                match = text.match(/(\\d{1,2}-\\d{1,2}\\s+\\d{1,2}:\\d{1,2})/);
                                if (match) time = match[1];
                            }
                            
                            if (title.length > 5) {
                                results.push({
                                    title: title.substring(0, 150),
                                    time: time,
                                    url: a.href
                                });
                            }
                        }
                    });
                    
                    return results;
                }""", target_count)
                
                for item in items:
                    uid = item['title'][:30]
                    if uid not in seen:
                        seen.add(uid)
                        results.append(item)
                
                print(f"ğŸ“Š [ç¬¬{scroll_round+1}è½®] é‡‡é›†: {len(results)} æ¡")
                
                if len(results) >= target_count:
                    break
                
                # æ»šåŠ¨åŠ è½½æ›´å¤š
                page.keyboard.press("End")
                page.mouse.wheel(0, 1000)
                time.sleep(2)
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
        finally:
            browser.close()
    
    # è¿”å›å‰Næ¡ï¼ˆä¿æŒé¡µé¢é¡ºåºï¼‰
    return results[:target_count]

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python gelonghui_scraper.py <å…³é”®è¯> [æ•°é‡] [--json]")
        print("ç¤ºä¾‹: python gelonghui_scraper.py å°ç±³é›†å›¢ 20")
        sys.exit(1)
    
    # è§£æå‚æ•°
    keyword = sys.argv[1]
    limit = 20
    json_mode = False
    
    for arg in sys.argv[2:]:
        if arg == '--json':
            json_mode = True
        elif arg.isdigit():
            limit = int(arg)
    
    # JSON æ¨¡å¼ï¼šé™é»˜è¿è¡Œï¼Œåªè¾“å‡º JSON
    if json_mode:
        import json as json_lib
        import io, sys as sys_module
        # æŠ‘åˆ¶ print è¾“å‡º
        old_stdout = sys_module.stdout
        sys_module.stdout = io.StringIO()
        data = scrape_gelonghui(keyword, limit)
        sys_module.stdout = old_stdout
        print(json_lib.dumps(data, ensure_ascii=False))
        return
    
    # æ™®é€šæ¨¡å¼
    print(f"{'='*50}")
    print(f"ğŸ“° æ ¼éš†æ±‡çˆ¬è™« | {keyword} | ç›®æ ‡: {limit}")
    print(f"{'='*50}")
    
    start = time.time()
    data = scrape_gelonghui(keyword, limit)
    elapsed = time.time() - start
    
    if data:
        filename = f"{keyword}_æ ¼éš†æ±‡_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {keyword} æ ¼éš†æ±‡èµ„è®¯\n\n")
            f.write(f"> é‡‡é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"> æ•°é‡: {len(data)}\n")
            f.write(f"> è€—æ—¶: {elapsed:.1f}ç§’\n")
            f.write(f"> æ’åº: æŒ‰æ—¶é—´å€’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰\n\n---\n\n")
            
            for i, item in enumerate(data, 1):
                f.write(f"## {i}. {item['title']}\n\n")
                if item.get('time'):
                    f.write(f"- **æ—¶é—´**: {item['time']}\n")
                if item.get('url'):
                    f.write(f"- **é“¾æ¥**: {item['url']}\n")
                f.write("\n")
        
        print(f"\n{'='*50}")
        print(f"âœ… å®Œæˆ: {len(data)}æ¡ | {elapsed:.1f}ç§’")
        print(f"ğŸ“„ ä¿å­˜: {filename}")
        print(f"{'='*50}")
    else:
        print(f"\nâš ï¸ æ— æ•°æ® | {elapsed:.1f}ç§’")

if __name__ == "__main__":
    main()

